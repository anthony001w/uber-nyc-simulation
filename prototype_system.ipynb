{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae7ec2-70ed-461e-a033-95ce09549993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d13a3d-94c4-4026-aa6a-40e1154a43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_data = pd.read_pickle('arrival_and_dropoff_distributions')\n",
    "hourly_arrival_rate =  pickup_data.apply(lambda item: item[0])\n",
    "dropoff_frequency  = pickup_data.apply(lambda  item: item[1] / item[1].sum())\n",
    "trip_time_data = pd.read_csv('trip_time_means.csv', index_col = 'pulocationid')\n",
    "trip_time_data.columns = trip_time_data.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8765d-d8c3-410f-9e4a-4008d3f1c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217383b-00b7-402e-a310-f06fe45632c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_arrivals_per_zone(zone_hourly_arrivals = hourly_arrival_rate, \n",
    "                               zone_dropoff_frequencies = dropoff_frequency, \n",
    "                               zone_to_zone_times = trip_time_data, \n",
    "                               one_list = True):\n",
    "    \n",
    "    #check to make sure the indices match\n",
    "    assert (zone_hourly_arrivals.index == zone_dropoff_frequencies.index).all()\n",
    "    assert (zone_hourly_arrivals.index == zone_to_zone_times.index).all()\n",
    "    \n",
    "    zone_arrivals = []\n",
    "    #for each zone, generate a day's worth of arrivals\n",
    "    for i in zone_hourly_arrivals.index:\n",
    "        \n",
    "        hourly_rates = zone_hourly_arrivals.loc[i]\n",
    "        dropoff_dist = zone_dropoff_frequencies.loc[i]\n",
    "        zone_service_times = zone_to_zone_times.loc[i]\n",
    "                \n",
    "        max_rate = hourly_rates.max()\n",
    "        #rate = max_rate / 60 minutes (since max_rate is in minutes)\n",
    "        #input the inverse as the mean interarrival time (scale parameter for np.random.exponential)\n",
    "        temp_interarrivals = np.random.exponential(scale = 60/max_rate, size = 25000)\n",
    "        \n",
    "        #this cuts off interarrivals at 1 day\n",
    "        interarrivals = temp_interarrivals[temp_interarrivals.cumsum() <= 24*60]\n",
    "        arrivals = interarrivals.cumsum()\n",
    "                \n",
    "        #thinning process\n",
    "        #uses constant hourly rate (like a 24 part step function) to generate the thinning probabilities\n",
    "        keep_probability = (hourly_rates[(arrivals // 60).astype(int)] / max_rate).values\n",
    "        unif = np.random.uniform(size = arrivals.shape[0])\n",
    "        kept_arrivals = arrivals[unif <= keep_probability]\n",
    "                \n",
    "        #for each arrival generate from the dropoff distribution\n",
    "        dropoffs = np.random.choice(dropoff_dist.index, size = kept_arrivals.shape[0], p = dropoff_dist)\n",
    "                              \n",
    "        #generate data in the form of (time, dropoff location id, pickup location id)\n",
    "        arrival_data = np.vstack([kept_arrivals, dropoffs, i*np.ones(kept_arrivals.shape[0])]).T\n",
    "        \n",
    "        #format into dataframe\n",
    "        arrival_df = pd.DataFrame(data = arrival_data, columns = ['time','dolocationid','pulocationid'])\n",
    "        \n",
    "        #each arrival, generate a service time from the service time distributions\n",
    "        #this is SLOW\n",
    "        services = [np.random.exponential(mean) for mean in zone_service_times[arrival_df.dolocationid]]\n",
    "                \n",
    "        arrival_df['service'] = services\n",
    "        \n",
    "        zone_arrivals.append(arrival_df)\n",
    "    \n",
    "    #if one list, then combine everything into one big arrival matrix\n",
    "    #otherwise, just return the list of arrival dataframes\n",
    "    if one_list:\n",
    "        zone_arrivals = pd.concat(zone_arrivals).sort_values('time').reset_index(drop=True)\n",
    "    \n",
    "    return zone_arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadce3a7-8f11-49c1-a43d-1b3ff27f9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from city_elements import *\n",
    "from city import *\n",
    "from event_list import *\n",
    "\n",
    "def simulate_with_individual_drivers(arrivals,\n",
    "                                     driver_distribution = 'proportional',\n",
    "                                     driver_count = 10000,\n",
    "                                     odmatrix = trip_time_data):\n",
    "    #convert arrivals into passengers, and then into events\n",
    "    passengers = []\n",
    "    drivers = []\n",
    "    \n",
    "    arrival_events = deque()\n",
    "    for a in arrivals.values:\n",
    "        p = Passenger(a[0], a[1], a[2], a[3])\n",
    "        passengers.append(p)\n",
    "        arrival_events.append(Arrival(p))\n",
    "    \n",
    "    event_list = EventList(arrival_events)\n",
    "    \n",
    "    #setup drivers and zones based on driver_distribution parameter\n",
    "    #everything is under the city class\n",
    "    if driver_distribution == 'proportional':\n",
    "        \n",
    "        zones = []\n",
    "        \n",
    "        #number of drivers per zone\n",
    "        dcounts = driver_count * (arrivals.groupby('pulocationid')['time'].count() / arrivals.shape[0])\n",
    "        dcounts = np.floor(dcounts)\n",
    "        \n",
    "        for i in range(1,264):\n",
    "            if i in dcounts.index:\n",
    "                temp_set = set()\n",
    "                for j in range(int(dcounts.loc[i])):\n",
    "                    d = Driver(i)\n",
    "                    temp_set.add(d)\n",
    "                    drivers.append(d)\n",
    "                zones.append(Zone(zone_id = i, driver_set = temp_set))\n",
    "            else:\n",
    "                zones.append(Zone(zone_id = i, driver_set = set()))\n",
    "        \n",
    "        for i in range(driver_count - len(drivers)):\n",
    "            z = np.random.choice(np.arange(1,264))\n",
    "            d = Driver(z)\n",
    "            drivers.append(d)\n",
    "            \n",
    "            for zone in zones:\n",
    "                if zone.zone == z:\n",
    "                    zone.add_driver(d)\n",
    "                    break\n",
    "                    \n",
    "        city = City('NYC', zones, drivers, odmatrix)\n",
    "            \n",
    "    #iterate through the event list until no events left\n",
    "    pbar = tqdm(total = arrivals.shape[0], position = 0, leave = True)\n",
    "    while not event_list.is_finished():\n",
    "        \n",
    "        event = event_list.iterate_next_event()\n",
    "        \n",
    "        #based on the type of event\n",
    "        if event.type == 'Arrival':\n",
    "            result = city.process_arrival_event(event)\n",
    "            if result is not None:\n",
    "                event_list.insert_event(result)\n",
    "            \n",
    "        elif event.type == 'Movement':\n",
    "            result = city.process_movement_event(event)\n",
    "            if result is not None:\n",
    "                event_list.insert_event(result)\n",
    "            \n",
    "        elif event.type == 'Trip':\n",
    "            pbar.update(1)\n",
    "            result = city.process_trip_event(event)\n",
    "            if result is not None:\n",
    "                event_list.insert_event(result)        \n",
    "                \n",
    "    return passengers, drivers, city, event_list\n",
    "\n",
    "def simulate_n_days(n,\n",
    "                    driver_distribution = 'proportional',\n",
    "                    driver_count = 15000):\n",
    "    #just keep 1 driver history bc it takes up too much memory\n",
    "    #keep all the waiting time information in dataframes\n",
    "    passenger_details = []\n",
    "    driver_history = None\n",
    "    city_history = None\n",
    "    \n",
    "    for i in range(n):\n",
    "        print(f'--- Day {i} ---')\n",
    "        arrivals = generate_arrivals_per_zone()\n",
    "        p, d, c, e = simulate_with_individual_drivers(arrivals, \n",
    "                                                      driver_distribution = driver_distribution, \n",
    "                                                      driver_count = driver_count)\n",
    "        waiting_times = np.array([(pe.time, pe.start, pe.end, pe.service, pe.departure_time, pe.waiting_time()) for pe in p])\n",
    "        waiting_times = pd.DataFrame(waiting_times, columns = ['arrival_time','starting zone', 'ending zone','service_time','departure_time','waiting_time'])\n",
    "        waiting_times['arrival_hour'] = waiting_times.arrival_time//60\n",
    "        waiting_times['replication'] = i\n",
    "        \n",
    "        passenger_details.append(waiting_times)\n",
    "        print(f'Average Waiting Time: {waiting_times.waiting_time.mean()}')\n",
    "        print(f'Median Waiting Time: {np.median(waiting_times.waiting_time)}')\n",
    "        print(f'Simulation System Speed: {e.timed_stats}')\n",
    "        \n",
    "        if i == n - 1:\n",
    "            driver_history = d\n",
    "            city_history = c\n",
    "    \n",
    "    return pd.concat(passenger_details), driver_history, city_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d24cb5-62dc-45ef-9b12-7ab860be55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_details, dhistory, chistory = simulate_n_days(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349f2e3-5058-4a61-9946-ecbc29fe3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "\n",
    "def normalize(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "grouped_by_hour = waiting_times.groupby('arrival_hour').agg({'waiting_time':'mean'})\n",
    "sns.lineplot(x = grouped_by_hour.index, y = grouped_by_hour.values[:,0],ax = ax[0], label = 'avg waiting time')\n",
    "sns.lineplot(x = np.arange(0,24), y = normalize(hourly_arrival_rate.sum()), label = 'arrival rate norm', ax = ax[1], color = 'orange')\n",
    "sns.lineplot(x = grouped_by_hour.index, y = normalize(grouped_by_hour.values[:,0]), label = 'avg waiting time norm', ax = ax[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
