{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ae7ec2-70ed-461e-a033-95ce09549993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d13a3d-94c4-4026-aa6a-40e1154a43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulocationid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>19.037500</td>\n",
       "      <td>17.794296</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.540476</td>\n",
       "      <td>15.923260</td>\n",
       "      <td>34.650000</td>\n",
       "      <td>100.883333</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.259722</td>\n",
       "      <td>6.489705</td>\n",
       "      <td>22.533333</td>\n",
       "      <td>85.900000</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.073516</td>\n",
       "      <td>2.869861</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">105</th>\n",
       "      <th>259</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69169 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean        std        min         max  count\n",
       "pulocationid                                                        \n",
       "1            1    19.037500  17.794296   2.716667   55.000000    8.0\n",
       "             2     0.000000   0.000000   0.000000    0.000000    0.0\n",
       "             3    54.540476  15.923260  34.650000  100.883333   14.0\n",
       "             4    34.259722   6.489705  22.533333   85.900000  186.0\n",
       "             5    25.073516   2.869861  17.350000   43.750000   86.0\n",
       "...                     ...        ...        ...         ...    ...\n",
       "105          259   0.000000   0.000000   0.000000    0.000000    0.0\n",
       "             260   0.000000   0.000000   0.000000    0.000000    0.0\n",
       "             261   0.000000   0.000000   0.000000    0.000000    0.0\n",
       "             262   0.000000   0.000000   0.000000    0.000000    0.0\n",
       "             263   0.000000   0.000000   0.000000    0.000000    0.0\n",
       "\n",
       "[69169 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickup_data = pd.read_pickle('arrival_and_dropoff_distributions')\n",
    "hourly_arrival_rate =  pickup_data.apply(lambda item: item[0])\n",
    "dropoff_frequency  = pickup_data.apply(lambda  item: item[1] / item[1].sum())\n",
    "trip_time_data = pd.read_parquet('trip_time_means')\n",
    "trip_time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3217383b-00b7-402e-a310-f06fe45632c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_arrivals_per_zone(zone_hourly_arrivals = hourly_arrival_rate, \n",
    "                               zone_dropoff_frequencies = dropoff_frequency, \n",
    "                               zone_to_zone_times = trip_time_data, \n",
    "                               one_list = True,\n",
    "                               show_progress_bar = False):\n",
    "    \n",
    "    #check to make sure the indices match\n",
    "    assert (zone_hourly_arrivals.index == zone_dropoff_frequencies.index).all()\n",
    "    \n",
    "    zone_arrivals = []\n",
    "    #for each zone, generate a day's worth of arrivals\n",
    "    iterable = zone_hourly_arrivals.index if not show_progress_bar else tqdm(zone_hourly_arrivals.index, position = 0, leave = True)\n",
    "    for i in iterable:\n",
    "        \n",
    "        hourly_rates = zone_hourly_arrivals.loc[i]\n",
    "        dropoff_dist = zone_dropoff_frequencies.loc[i]\n",
    "        zone_service_times = zone_to_zone_times.loc[i]\n",
    "                \n",
    "        max_rate = hourly_rates.max()\n",
    "        #rate = max_rate / 60 minutes (since max_rate is in minutes)\n",
    "        #input the inverse as the mean interarrival time (scale parameter for np.random.exponential)\n",
    "        temp_interarrivals = np.random.exponential(scale = 60/max_rate, size = 25000)\n",
    "        \n",
    "        #this cuts off interarrivals at 1 day\n",
    "        interarrivals = temp_interarrivals[temp_interarrivals.cumsum() <= 24*60]\n",
    "        arrivals = interarrivals.cumsum()\n",
    "                \n",
    "        #thinning process\n",
    "        #uses constant hourly rate (like a 24 part step function) to generate the thinning probabilities\n",
    "        keep_probability = (hourly_rates[(arrivals // 60).astype(int)] / max_rate).values\n",
    "        unif = np.random.uniform(size = arrivals.shape[0])\n",
    "        kept_arrivals = arrivals[unif <= keep_probability]\n",
    "                \n",
    "        #for each arrival generate from the dropoff distribution\n",
    "        dropoffs = np.random.choice(dropoff_dist.index, size = kept_arrivals.shape[0], p = dropoff_dist)\n",
    "                              \n",
    "        #generate data in the form of (time, dropoff location id, pickup location id)\n",
    "        arrival_data = np.vstack([kept_arrivals, dropoffs, i*np.ones(kept_arrivals.shape[0])]).T\n",
    "        \n",
    "        #format into dataframe\n",
    "        arrival_df = pd.DataFrame(data = arrival_data, columns = ['time','dolocationid','pulocationid'])\n",
    "        \n",
    "        #each arrival, generate a service time from the service time distributions\n",
    "        #this is SLOW\n",
    "        if len(arrival_df) > 0:\n",
    "            services = [np.clip(np.random.normal(loc = info[0], scale = info[1]), info[2], info[3]) \n",
    "                        for info in zone_service_times.loc[arrival_df.dolocationid].values]\n",
    "\n",
    "            arrival_df['service'] = services\n",
    "\n",
    "            zone_arrivals.append(arrival_df)\n",
    "    \n",
    "    #if one list, then combine everything into one big arrival matrix\n",
    "    #otherwise, just return the list of arrival dataframes\n",
    "    if one_list:\n",
    "        zone_arrivals = pd.concat(zone_arrivals).sort_values('time').reset_index(drop=True)\n",
    "    \n",
    "    return zone_arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fadce3a7-8f11-49c1-a43d-1b3ff27f9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from city_elements import *\n",
    "from city import *\n",
    "from event_list import *\n",
    "\n",
    "def simulate_with_individual_drivers(arrivals,\n",
    "                                     driver_distribution = 'proportional',\n",
    "                                     driver_count = 10000,\n",
    "                                     odmatrix = trip_time_data):\n",
    "    #convert arrivals into passengers, and then into events\n",
    "    passengers = []\n",
    "    drivers = []\n",
    "    \n",
    "    arrival_events = deque()\n",
    "    for a in arrivals.values:\n",
    "        p = Passenger(a[0], a[1], a[2], a[3])\n",
    "        passengers.append(p)\n",
    "        arrival_events.append(Arrival(p))\n",
    "    \n",
    "    event_list = EventList(arrival_events)\n",
    "    \n",
    "    #setup drivers and zones based on driver_distribution parameter\n",
    "    #everything is under the city class\n",
    "    if driver_distribution == 'proportional':\n",
    "        \n",
    "        zones = []\n",
    "        \n",
    "        #number of drivers per zone\n",
    "        dcounts = driver_count * (arrivals.groupby('pulocationid')['time'].count() / arrivals.shape[0])\n",
    "        dcounts = np.floor(dcounts)\n",
    "        \n",
    "        for i in range(1,264):\n",
    "            if i in dcounts.index:\n",
    "                temp_set = set()\n",
    "                for j in range(int(dcounts.loc[i])):\n",
    "                    d = Driver(i)\n",
    "                    temp_set.add(d)\n",
    "                    drivers.append(d)\n",
    "                zones.append(Zone(zone_id = i, driver_set = temp_set))\n",
    "            else:\n",
    "                zones.append(Zone(zone_id = i, driver_set = set()))\n",
    "        \n",
    "        for i in range(driver_count - len(drivers)):\n",
    "            z = np.random.choice(np.arange(1,264))\n",
    "            d = Driver(z)\n",
    "            drivers.append(d)\n",
    "            \n",
    "            for zone in zones:\n",
    "                if zone.zone == z:\n",
    "                    zone.add_driver(d)\n",
    "                    break\n",
    "            \n",
    "        city = City('NYC', zones, drivers, odmatrix)\n",
    "            \n",
    "    #iterate through the event list until no events left\n",
    "    pbar = tqdm(total = arrivals.shape[0], position = 0, leave = True)\n",
    "    while not event_list.is_finished():\n",
    "        \n",
    "        event = event_list.iterate_next_event()\n",
    "        \n",
    "        result = city.process_event(event)\n",
    "        if event.type == 'Trip':\n",
    "            pbar.update(1)\n",
    "            \n",
    "        if result is not None:\n",
    "            event_list.insert_event(result)   \n",
    "                \n",
    "    return passengers, drivers, city, event_list\n",
    "\n",
    "def simulate_n_days(n,\n",
    "                    driver_distribution = 'proportional',\n",
    "                    driver_count = 15000):\n",
    "    #just keep 1 driver history bc it takes up too much memory\n",
    "    #keep all the waiting time information in dataframes\n",
    "    passenger_details = []\n",
    "    driver_history = None\n",
    "    city_history = None\n",
    "    \n",
    "    for i in range(n):\n",
    "        print(f'--- Day {i} ---')\n",
    "        arrivals = generate_arrivals_per_zone()\n",
    "        p, d, c, e = simulate_with_individual_drivers(arrivals, \n",
    "                                                      driver_distribution = driver_distribution, \n",
    "                                                      driver_count = driver_count)\n",
    "        waiting_times = np.array([(pe.time, pe.start, pe.end, pe.service, pe.departure_time, pe.waiting_time()) for pe in p])\n",
    "        waiting_times = pd.DataFrame(waiting_times, columns = ['arrival_time','starting zone', 'ending zone','service_time','departure_time','waiting_time'])\n",
    "        waiting_times['arrival_hour'] = waiting_times.arrival_time//60\n",
    "        waiting_times['replication'] = i\n",
    "        \n",
    "        passenger_details.append(waiting_times)\n",
    "        print(f'Average Waiting Time: {waiting_times.waiting_time.mean()}')\n",
    "        print(f'Median Waiting Time:{np.median(waiting_times.waiting_time)}')\n",
    "        print(f'Simulation System Speed: {e.timed_stats}')\n",
    "        \n",
    "        if i == n - 1:\n",
    "            driver_history = d\n",
    "            city_history = c\n",
    "    \n",
    "    return pd.concat(passenger_details), driver_history, city_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83aad776-7604-43a3-8990-df48ec6c43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c354140a04f7f9c61c0e37f5c6c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arrivals = generate_arrivals_per_zone(show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d24cb5-62dc-45ef-9b12-7ab860be55fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac66acc6270f40238b29364ee24878b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/456483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p,d,c,e = simulate_with_individual_drivers(arrivals, driver_count = 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc41184-ef5e-4d46-8289-a97e5e3f77eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insertion speed': [10.188461780548096, 672177],\n",
       " 'pop speed': [0.3056371212005615, 1128660],\n",
       " 'search speed': [42.39673066139221, 672177]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.timed_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb51bb6-d0f1-4e8e-ae97-8280202867a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generating_movement_times': [76.42599129676819, 215694],\n",
       " 'choose_driver': [4.171963214874268, 216382]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.timed_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb6685-cfde-4792-afa8-bc89f82e7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "passe = np.array([pe.waiting_time() for pe in p]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435780e4-a7f1-45b8-98b6-7160b7173a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(passe[passe>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349f2e3-5058-4a61-9946-ecbc29fe3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "\n",
    "def normalize(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "grouped_by_hour = waiting_times.groupby('arrival_hour').agg({'waiting_time':'mean'})\n",
    "sns.lineplot(x = grouped_by_hour.index, y = grouped_by_hour.values[:,0],ax = ax[0], label = 'avg waiting time')\n",
    "sns.lineplot(x = np.arange(0,24), y = normalize(hourly_arrival_rate.sum()), label = 'arrival rate norm', ax = ax[1], color = 'orange')\n",
    "sns.lineplot(x = grouped_by_hour.index, y = normalize(grouped_by_hour.values[:,0]), label = 'avg waiting time norm', ax = ax[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
